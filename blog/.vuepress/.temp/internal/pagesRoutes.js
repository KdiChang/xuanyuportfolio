export const pagesRoutes = [
  ["v-f0388862","/links/",{"title":"Links"},["/links/index.html","/links/README.md"]],
  ["v-6ff109d6","/post/2017/06/09/my-high-school-life/",{"title":"高中生活回忆录","subtitle":"My High School Life","date":"2017-06-09T00:00:00.000Z","tags":["摸鱼"],"headerImage":"/img/in-post/2017-06-09/header.jpeg","excerpt":"<p>总得有地方来存我当年写的小作文。</p>\n"},["/post/2017/06/09/my-high-school-life/index.html","/posts/2017-06-09-my-high-school-life.html","/posts/2017-06-09-my-high-school-life.md"]],
  ["v-f931cad4","/post/2018/02/17/nlp-resource/",{"title":"NLP 不入门直接放弃","subtitle":"How to give up NLP","date":"2018-02-17T00:00:00.000Z","tags":["NLP"],"headerImage":"/img/in-post/2018-02-17/header.jpg","excerpt":"<p>来源：<a href=\"https://towardsdatascience.com/how-to-get-started-in-nlp-6a62aa4eaeff\" target=\"_blank\" rel=\"noopener noreferrer\">Melanie Tosik（Twitter:@meltomene）列出的 NLP 学习资源清单</a></p>\n"},["/post/2018/02/17/nlp-resource/index.html","/posts/2018-02-17-nlp-resource.html","/posts/2018-02-17-nlp-resource.md"]],
  ["v-4d501497","/post/2018/09/01/p-value/",{"title":"p-value","subtitle":"Something about p-value","date":"2018-09-01T00:00:00.000Z","tags":["Math"],"headerImage":"/img/in-post/2018-09-01/header.jpeg","excerpt":"<p>一个例子：一个正常的硬币，在被投掷无数次后，结果一定会是正面朝上和反面朝上各占 50%。如果想要知道一个硬币是否正常，是否被做过手脚，显然是没办法投掷无数次的。因此，只能用有限的结果来判断“该硬币是否正常”。</p>\n"},["/post/2018/09/01/p-value/index.html","/posts/2018-09-01-p-value.html","/posts/2018-09-01-p-value.md"]],
  ["v-f5c7c5d2","/post/2018/11/11/zelda-horizon/",{"title":"《塞尔达传说：荒野之息》&《地平线：黎明时分》联动","subtitle":"The Legend of Zelda: Breath of the Wild & Horizon: Zero Dawn","date":"2018-11-11T00:00:00.000Z","tags":["摸鱼"],"headerImage":"/img/in-post/2018-11-11/header.jpg","excerpt":"<p>摸鱼。（等等你代码写完了吗......</p>\n"},["/post/2018/11/11/zelda-horizon/index.html","/posts/2018-11-11-zelda-horizon.html","/posts/2018-11-11-zelda-horizon.md"]],
  ["v-b0ab6524","/post/2018/11/30/dynamo/",{"title":"Dynamo 论文总结","subtitle":"Note about Dynamo","date":"2018-11-30T00:00:00.000Z","tags":["分布式"],"headerImage":"/img/in-post/2018-11-30/header.jpg","excerpt":"<p>阅读论文 <a href=\"https://link.jianshu.com/?t=http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">Dynamo: Amazon’s Highly Available Key-value Store</a> 后的一些总结。</p>\n"},["/post/2018/11/30/dynamo/index.html","/posts/2018-11-30-dynamo.html","/posts/2018-11-30-dynamo.md"]],
  ["v-b9322342","/post/2018/12/22/note-of-linear-algebra/",{"title":"线性代数笔记","subtitle":"Note of Linear Algebra","date":"2018-12-22T00:00:00.000Z","tags":["Math"],"headerImage":"/img/in-post/2018-12-22/header.jpg","excerpt":"<p>MIT 18.06 / Stanford CS229 (Linear Algebra 部分)</p>\n"},["/post/2018/12/22/note-of-linear-algebra/index.html","/posts/2018-12-22-note-of-linear-algebra.html","/posts/2018-12-22-note-of-linear-algebra.md"]],
  ["v-adac814c","/post/2019/02/15/rnn-with-its-friends/",{"title":"RNN 和它的朋友们","subtitle":"RNN, LSTM, GRU ...","date":"2019-02-15T00:00:00.000Z","tags":["Deep Learning"],"headerImage":"/img/in-post/2019-02-15/header.jpg","excerpt":"<p>对 RNN 系成员的一些总结。</p>\n"},["/post/2019/02/15/rnn-with-its-friends/index.html","/posts/2019-02-15-rnn-with-its-friends.html","/posts/2019-02-15-rnn-with-its-friends.md"]],
  ["v-5e4a66aa","/post/2019/04/03/racf-experiment/",{"title":"RACF 实验","subtitle":"RACF Experiments","date":"2019-04-03T00:00:00.000Z","tags":["主机"],"headerImage":"/img/in-post/2019-04-03/header.png","excerpt":"<p>对我认为的本科最难的课（2333）第一次实验的流水账式记录。</p>\n<p>希望早日脱离大型机的苦海，阿门。</p>\n"},["/post/2019/04/03/racf-experiment/index.html","/posts/2019-04-03-racf-experiment.html","/posts/2019-04-03-racf-experiment.md"]],
  ["v-5ea9df6a","/post/2019/07/06/last-three-years/",{"title":"对过去三年的碎碎念","subtitle":"像样的麻婆豆腐是这个令人讨厌的世界上的唯一的光","date":"2019-07-06T00:00:00.000Z","tags":["摸鱼"],"headerImage":"/img/in-post/2019-07-06/header.jpg","excerpt":"<p>封面图是《塞尔达传说：荒野之息》里的利特族族长 Kaneli，来自 <a href=\"https://wroage.tumblr.com/image/185206416422\" target=\"_blank\" rel=\"noopener noreferrer\">@wroage (tumblr)</a>。利特族真是一个毛茸茸的好族。</p>\n"},["/post/2019/07/06/last-three-years/index.html","/posts/2019-07-06-last-three-years.html","/posts/2019-07-06-last-three-years.md"]],
  ["v-4053c498","/post/2020/02/24/the-enigmatic-appeal-of-video-games-greatest-bards/",{"title":"「译」游戏中的游吟诗人的神秘魅力","subtitle":"The world’s second-oldest profession has a long history of nonviolence in video games","date":"2020-02-24T00:00:00.000Z","tags":["摸鱼"],"headerImage":"/img/in-post/2020-02-24/header.jpg","excerpt":"<p>翻译自 <a href=\"https://egmnow.com/\" target=\"_blank\" rel=\"noopener noreferrer\">EGM</a> 上的文章：<a href=\"https://egmnow.com/toss-a-coin-the-enigmatic-appeal-of-video-games-greatest-bards/\" target=\"_blank\" rel=\"noopener noreferrer\"><v-icon name=\"ri-link-m\" scale=\"0.9\"/> <em>Toss a Coin: The Enigmatic Appeal of Gaming’s Greatest Bards</em></a>。</p>\n"},["/post/2020/02/24/the-enigmatic-appeal-of-video-games-greatest-bards/index.html","/posts/2020-02-24-the-enigmatic-appeal-of-video-games-greatest-bards.html","/posts/2020-02-24-the-enigmatic-appeal-of-video-games-greatest-bards.md"]],
  ["v-4125e87c","/post/2020/02/29/image-aesthetic-assessment/",{"title":"图像美感评估","subtitle":"A Survey on Image Aesthetic Assessment","date":"2020-02-29T00:00:00.000Z","tags":["CV"],"headerImage":"/img/in-post/2020-02-29/header.jpeg","excerpt":"<p>对图像美感评估（Image Aesthetic Assessment）领域的简单调研，到时候大概可以直接复制粘贴进毕业论文里。</p>\n"},["/post/2020/02/29/image-aesthetic-assessment/index.html","/posts/2020-02-29-image-aesthetic-assessment.html","/posts/2020-02-29-image-aesthetic-assessment.md"]],
  ["v-23c8e74f","/post/2020/03/17/papers-reading/",{"title":"三月大锅烩","subtitle":"Papers Reading: Machine Translation / Text Classification / Image Captioning","date":"2020-03-17T00:00:00.000Z","tags":["NLP","CV","Machine Translation","Text Classification","Image Captioning","Image Aesthetic Captioning"],"headerImage":"/img/in-post/2020-03-17/header.jpg","excerpt":"<p>看过的关于机器翻译 / 文本摘要 / 图像描述的论文的总结，到时候大概也可以直接复制粘贴进毕业论文里。</p>\n"},["/post/2020/03/17/papers-reading/index.html","/posts/2020-03-17-papers-reading.html","/posts/2020-03-17-papers-reading.md"]],
  ["v-647759ba","/post/2020/07/10/messy-notes-nlp/",{"title":"乱七八糟的知识点","subtitle":"Messy Notes (NLP)","date":"2020-07-10T00:00:00.000Z","tags":["NLP"],"headerImage":"/img/in-post/2020-07-10/header.jpg","excerpt":"<p>菜鸡在失学失业的惊慌失措之下的胡乱总结，又因为懒惰压制了惊慌失措所以并没有总结多少...</p>\n"},["/post/2020/07/10/messy-notes-nlp/index.html","/posts/2020-07-10-messy-notes-nlp.html","/posts/2020-07-10-messy-notes-nlp.md"]],
  ["v-a991a318","/post/2020/07/17/transformer/",{"title":"Transformer","subtitle":"试图理一理 Transformer","date":"2020-07-17T00:00:00.000Z","tags":["NLP"],"headerImage":"/img/in-post/2020-07-17/header.jpg","excerpt":"<p><strong>Attention Is All You Need.</strong> <em>Ashish Vaswani, et al.</em> NIPS 2017. <a href=\"https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">[Paper]</a> <a href=\"https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py\" target=\"_blank\" rel=\"noopener noreferrer\">[Code]</a></p>\n"},["/post/2020/07/17/transformer/index.html","/posts/2020-07-17-transformer.html","/posts/2020-07-17-transformer.md"]],
  ["v-51506fc9","/post/2020/08/05/meta-learning/",{"title":"元学习：一种套娃算法","subtitle":"Meta Learning: Learning to Learn","date":"2020-08-05T00:00:00.000Z","tags":["Meta Learning","Deep Learning"],"headerImage":"/img/in-post/2020-08-05/header.jpg","excerpt":"<p>continual learning 方向 19 年之后的<a href=\"https://note.zxh.io/papers/dl/continual-learning.html#meta-learning\" target=\"_blank\" rel=\"noopener noreferrer\">几篇论文</a>搞出了一个套 meta learning 框架（主要是 MAML 这种 optimization-based 的方法）的新思路。</p>\n"},["/post/2020/08/05/meta-learning/index.html","/posts/2020-08-05-meta-learning.html","/posts/2020-08-05-meta-learning.md"]],
  ["v-0bb6fbf0","/post/2020/08/16/bayesian-neural-network/",{"title":"贝叶斯神经网络","subtitle":"万恶的贝叶斯嗷，真的学得会吗","date":"2020-08-16T00:00:00.000Z","tags":["Machine Learning","Deep Learning","Math","Bayesian"],"headerImage":"/img/in-post/2020-08-16/header.png","excerpt":"<p>Radford Neal: I don't necessarily think that the Bayesian method is the best thing to do in all cases...</p>\n"},["/post/2020/08/16/bayesian-neural-network/index.html","/posts/2020-08-16-bayesian-neural-network.html","/posts/2020-08-16-bayesian-neural-network.md"]],
  ["v-a43d8888","/post/2020/08/22/bocd/",{"title":"BOCD","subtitle":"Bayesian Online Changepoint Detection","date":"2020-08-22T00:00:00.000Z","tags":["Machine Learning","Math","Bayesian"],"headerImage":"/img/in-post/2020-08-22/header.jpg","excerpt":"<p>给定一个数据序列，在某个时间点，数据的某个（或某些）参数可能由于系统性因素（而非偶然性因素）而突然发生变化，那么这个时间点被称为<strong>变点</strong>（changepoint）。</p>\n"},["/post/2020/08/22/bocd/index.html","/posts/2020-08-22-bocd.html","/posts/2020-08-22-bocd.md"]],
  ["v-5a59101e","/post/2020/08/24/regularization-based-continual-learning/",{"title":"Regularization-based Continual Learning","subtitle":"EWC / Online EWC / IS / MAS ...","date":"2020-08-24T00:00:00.000Z","tags":["Deep Learning","Continual Learning","Bayesian"],"headerImage":"/img/in-post/2020-08-24/header.jpg","excerpt":"<p>基于正则（regularization-based）的持续学习：用一个表示参数重要程度的正则项来控制参数在未来的任务中的更新幅度。</p>\n"},["/post/2020/08/24/regularization-based-continual-learning/index.html","/posts/2020-08-24-regularization-based-continual-learning.html","/posts/2020-08-24-regularization-based-continual-learning.md"]],
  ["v-3fdbb946","/post/2020/09/04/bayesian-meta-learning/",{"title":"Bayesian MAML","subtitle":"MAML 的贝叶斯解释","date":"2020-09-04T00:00:00.000Z","tags":["Deep Learning","Meta Learning","Bayesian"],"headerImage":"/img/in-post/2020-09-04/header.jpg","excerpt":"<p>为了引入不确定性<s>和多找一个发论文的话题</s>，MAML 还可以用贝叶斯视角来理解。</p>\n"},["/post/2020/09/04/bayesian-meta-learning/index.html","/posts/2020-09-04-bayesian-meta-learning.html","/posts/2020-09-04-bayesian-meta-learning.md"]],
  ["v-6acef3fe","/post/2020/10/07/my-blog/",{"title":"关于博客的碎碎念","subtitle":"部署、优化以及乱七八糟的事","date":"2020-10-07T00:00:00.000Z","tags":["摸鱼"],"headerImage":"/img/in-post/2020-10-07/header.jpg","excerpt":"<p>“虽然研究进度堪忧，但鱼还是要摸的”，在这样的理念的驱动下，菜鸡最终折腾出了一个目前看上去还算可以的方案。</p>\n"},["/post/2020/10/07/my-blog/index.html","/posts/2020-10-07-my-blog.html","/posts/2020-10-07-my-blog.md"]],
  ["v-4b441409","/post/2021/01/01/new-year/",{"title":"新年快乐","subtitle":"Happy New Year 2021","date":"2021-01-01T00:00:00.000Z","tags":["摸鱼"],"headerImage":"/img/in-post/2021-01-01/header.jpg","excerpt":"<p>太长不看版：顺位第一的新年愿望是能成为一个温暖的人类，如果这个愿望今年无法实现，那就先当一个正常一些的人类吧。</p>\n"},["/post/2021/01/01/new-year/index.html","/posts/2021-01-01-new-year.html","/posts/2021-01-01-new-year.md"]],
  ["v-52e160df","/post/2021/01/28/lets-talk-about-pytorch/",{"title":"凌乱的 PyTorch 笔记","subtitle":"PyTorch 能有什么坏心思呢","date":"2021-01-28T00:00:00.000Z","tags":["Deep Learning"],"headerImage":"/img/in-post/2021-01-28/header.jpg","excerpt":"<p>记录一些 PyTorch 的细节。</p>\n"},["/post/2021/01/28/lets-talk-about-pytorch/index.html","/posts/2021-01-28-lets-talk-about-pytorch.html","/posts/2021-01-28-lets-talk-about-pytorch.md"]],
  ["v-ef15f804","/post/2021/04/26/pc-algorithm/",{"title":"PC 算法","subtitle":"贝叶斯网络与其结构学习算法","date":"2021-04-26T00:00:00.000Z","tags":["Machine Learning","Bayesian"],"headerImage":"/img/in-post/2021-04-26/header.jpg","excerpt":"<p>把大三的时候在实验室摸鱼看贝叶斯网络和 PC 算法时写的笔记整理到这里来，免得哪天我换电脑时把笔记搞没了。</p>\n"},["/post/2021/04/26/pc-algorithm/index.html","/posts/2021-04-26-pc-algorithm.html","/posts/2021-04-26-pc-algorithm.md"]],
  ["v-0abd0086","/post/2021/06/12/svm/",{"title":"支持向量机","subtitle":"Support Vector Machine (SVM)","date":"2021-06-12T00:00:00.000Z","tags":["Machine Learning"],"headerImage":"/img/in-post/2021-06-12/header.jpg","excerpt":"<p>SVM（Support Vector Machine，支持向量机）是一种二类分类模型，目标是在特征空间上找到间隔最大化的超平面。</p>\n"},["/post/2021/06/12/svm/index.html","/posts/2021-06-12-svm.html","/posts/2021-06-12-svm.md"]],
  ["v-72b9d083","/post/2021/07/27/fisher-information-matrix/",{"title":"Fisher 信息矩阵","subtitle":"Fisher Information Matrix","date":"2021-07-27T00:00:00.000Z","tags":["Machine Learning","Math"],"headerImage":"/img/in-post/2021-07-27/header.jpeg","excerpt":"<p>Fisher 信息矩阵的数学意义和直观上的理解。</p>\n"},["/post/2021/07/27/fisher-information-matrix/index.html","/posts/2021-07-27-fisher-information-matrix.html","/posts/2021-07-27-fisher-information-matrix.md"]],
  ["v-35b0adfe","/post/2021/07/28/natural-gradient/",{"title":"自然梯度下降","subtitle":"Natural Gradient Decent","date":"2021-07-28T00:00:00.000Z","tags":["Machine Learning"],"headerImage":"/img/in-post/2021-07-28/header.jpeg","excerpt":"<p>自然梯度下降（Natural Gradient Decent）把参数看成一种概率分布，然后使用 KL 散度而不是欧氏距离来作为距离的度量，从而更好地描述更新后的分布和原分布有多大的不同。</p>\n"},["/post/2021/07/28/natural-gradient/index.html","/posts/2021-07-28-natural-gradient.html","/posts/2021-07-28-natural-gradient.md"]],
  ["v-7f60f4e6","/post/2021/08/31/attention-conv/",{"title":"Attention / Conv 大锅烩","subtitle":"Self-Attentions and Convolutions","date":"2021-08-31T00:00:00.000Z","tags":["Deep Learning"],"headerImage":"/img/in-post/2021-08-31/header.jpg","excerpt":"<p>长期记录和实现看过的各种论文里的自注意力和卷积机制，咕咕咕，实现地址在：<a href=\"https://github.com/Renovamen/torchop\" target=\"_blank\" rel=\"noopener noreferrer\"><v-icon name=\"ri-link-m\" scale=\"0.9\"/> Github</a></p>\n"},["/post/2021/08/31/attention-conv/index.html","/posts/2021-08-31-attention-conv.html","/posts/2021-08-31-attention-conv.md"]],
  ["v-9728b424","/post/2022/01/29/travel-to-boston/",{"title":"波士顿漫游指南","subtitle":"How to Travel to Boston","date":"2022-01-29T00:00:00.000Z","tags":["摸鱼"],"headerImage":"/img/in-post/2022-01-29/header.jpeg","excerpt":"<p>在 gap 了一年，又上了一学期网课以后，我终于来了波士顿。</p>\n"},["/post/2022/01/29/travel-to-boston/index.html","/posts/2022-01-29-travel-to-boston.html","/posts/2022-01-29-travel-to-boston.md"]],
  ["v-44755bac","/post/2022/02/21/new-year-2022/",{"title":"2022 新年快乐","subtitle":"Gap Year 的结束，摸鱼与快乐","date":"2022-02-21T00:00:00.000Z","tags":["摸鱼"],"headerImage":"/img/in-post/2022-02-21/header.jpeg","excerpt":"<p>不管是按公历新年，还是按中国新年，在这个点说新年快乐都显得格格不入，<s>但反正也没人看也就无所谓了</s>。</p>\n"},["/post/2022/02/21/new-year-2022/index.html","/posts/2022-02-21-new-year-2022.html","/posts/2022-02-21-new-year-2022.md"]],
  ["v-3706649a","/404.html",{"title":""},["/404"]],
  ["v-15534fdd","/tags/",{"title":"Tags"},["/tags/index.html"]],
  ["v-8daa1a0e","/",{"title":"Home"},["/index.html"]],
  ["v-4975443b","/tags/%E6%91%B8%E9%B1%BC/",{"title":"摸鱼 | Tags"},["/tags/摸鱼/","/tags/%E6%91%B8%E9%B1%BC/index.html"]],
  ["v-cd1c854c","/tags/nlp/",{"title":"NLP | Tags"},["/tags/nlp/index.html"]],
  ["v-d69a272c","/tags/math/",{"title":"Math | Tags"},["/tags/math/index.html"]],
  ["v-6b6ec9b1","/tags/%E5%88%86%E5%B8%83%E5%BC%8F/",{"title":"分布式 | Tags"},["/tags/分布式/","/tags/%E5%88%86%E5%B8%83%E5%BC%8F/index.html"]],
  ["v-41393b66","/tags/deep-learning/",{"title":"Deep Learning | Tags"},["/tags/deep-learning/index.html"]],
  ["v-ee5373f6","/tags/%E4%B8%BB%E6%9C%BA/",{"title":"主机 | Tags"},["/tags/主机/","/tags/%E4%B8%BB%E6%9C%BA/index.html"]],
  ["v-abc76dc2","/tags/cv/",{"title":"CV | Tags"},["/tags/cv/index.html"]],
  ["v-7a1e6ec1","/tags/machine-translation/",{"title":"Machine Translation | Tags"},["/tags/machine-translation/index.html"]],
  ["v-75aa53c6","/tags/text-classification/",{"title":"Text Classification | Tags"},["/tags/text-classification/index.html"]],
  ["v-c5a62878","/tags/image-captioning/",{"title":"Image Captioning | Tags"},["/tags/image-captioning/index.html"]],
  ["v-24f09a43","/tags/image-aesthetic-captioning/",{"title":"Image Aesthetic Captioning | Tags"},["/tags/image-aesthetic-captioning/index.html"]],
  ["v-eb9c9fb4","/tags/meta-learning/",{"title":"Meta Learning | Tags"},["/tags/meta-learning/index.html"]],
  ["v-1241708e","/tags/machine-learning/",{"title":"Machine Learning | Tags"},["/tags/machine-learning/index.html"]],
  ["v-d0dc18b8","/tags/bayesian/",{"title":"Bayesian | Tags"},["/tags/bayesian/index.html"]],
  ["v-6cff85a0","/tags/continual-learning/",{"title":"Continual Learning | Tags"},["/tags/continual-learning/index.html"]],
  ["v-3a1f8885","/page/1/",{"title":"Home"},["/page/1/index.html"]],
  ["v-3a1f88a4","/page/2/",{"title":"Home"},["/page/2/index.html"]],
  ["v-3a1f88c3","/page/3/",{"title":"Home"},["/page/3/index.html"]],
]
